{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46fd3a72-fe24-40a5-ba87-4e0462337ab8",
   "metadata": {},
   "source": [
    "# 从零开始实现线性回归\n",
    "通过代码实现线性回归模型的构建、训练过程，进一步理解机器学习的整体流程\n",
    "\n",
    "包括数据流水线、损失函数和小批量随机梯度下降优化器等\n",
    "详细步骤如下:\n",
    "1. 生成训练数据\n",
    "2. 读取数据集（数据集批量分割）\n",
    "3. 初始化模型参数\n",
    "4. 定义模型\n",
    "5. 定义损失函数\n",
    "6. 定义优化器\n",
    "7. 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8769cbac-7770-4496-97e6-cd474a91b0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import d2l\n",
    "import torch\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34219c1-ea0c-4b73-8dd3-ad82e1607d6e",
   "metadata": {},
   "source": [
    "### 1. 生成训练数据集\n",
    "\n",
    "y = Xw + b + $\\epsilon$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d7bcc40-8eed-4793-81f7-f9a1b2de7ee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features shape: torch.Size([1000, 2])\n",
      "labels shape: torch.Size([1000, 1])\n"
     ]
    }
   ],
   "source": [
    "def synthetic_data(w, b, num_examples):\n",
    "    X = torch.normal(0, 1, (num_examples, len(w)))\n",
    "    y = torch.mv(X, w) + b\n",
    "    y += torch.normal(0, 0.01, y.shape)\n",
    "    return X, y.reshape((-1, 1))\n",
    "\n",
    "true_w = torch.tensor([2, -3.4])\n",
    "true_b = torch.tensor(4.2)\n",
    "num_examples = 1000\n",
    "features, labels = synthetic_data(true_w, true_b, num_examples)\n",
    "print(f'features shape: {features.shape}\\nlabels shape: {labels.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0acaed3-9a32-4378-9564-c20c4696fd90",
   "metadata": {},
   "source": [
    "### 2. 读取数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "add8c756-02cd-45d8-affe-6ce8fdd61d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_iter(batch_size, features, labels):\n",
    "    num_examples = len(features)\n",
    "    indices = list(range(num_examples))\n",
    "    random.shuffle(indices)\n",
    "    for i in range(0, num_examples, batch_size):\n",
    "        end_index = min(i + batch_size, num_examples)\n",
    "        batch_indices = indices[i:end_index]\n",
    "        yield features[batch_indices], labels[batch_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cace58cb-a20c-42bf-8dff-172156445793",
   "metadata": {},
   "source": [
    "### 3. 初始化模型参数\n",
    "从$N(\\mu = 0, \\sigma = 0.001)$的正态分布随机抽样初始化w 和 b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e52b4bb1-3671-4bf5-91cc-f655e1762cb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-5.8748e-05,  3.5632e-05], requires_grad=True),\n",
       " tensor(0.0004, requires_grad=True))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = torch.normal(0, 0.001, true_w.shape, requires_grad=True)\n",
    "b = torch.normal(0, 0.001, true_b.shape, requires_grad=True)\n",
    "w, b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c629cfae-5013-4ad6-8940-675083cd8050",
   "metadata": {},
   "source": [
    "### 4. 定义模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8645d11c-c144-4675-a622-649487e1bc68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linreg(X, w, b):\n",
    "    \"\"\"线性回归模型\"\"\"\n",
    "    return torch.mv(X, w) + b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749704e2-9684-4e7c-a5d2-93c5489dcbd8",
   "metadata": {},
   "source": [
    "### 5. 定义损失函数\n",
    "标签值是数值型，采用 MSE 作为损失函数\n",
    "$\\frac{1}{2}(y - \\hat{y})^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83d492a7-3bac-4c57-8226-30da804994e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5000)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def squared_loss(y_pred, y_true):\n",
    "    return (y_pred - y_true.reshape(y_pred.shape)) ** 2 / 2\n",
    "\n",
    "squared_loss(torch.tensor(99), torch.tensor(100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61f05dc-7f78-44f9-bcbb-fcf9ce383806",
   "metadata": {},
   "source": [
    "### 6. 定义优化算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45fcfe08-aaaa-400c-869b-ce7fd8f84f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sgd(params, lr, batch_size):\n",
    "    \"\"\"小批量随机梯度下降\"\"\"\n",
    "    with torch.no_grad():\n",
    "        for param in params:\n",
    "            param -= lr * param.grad / batch_size\n",
    "            param.grad.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2040984-702d-418b-9c6e-60478ab31ec0",
   "metadata": {},
   "source": [
    "### 7. 训练模型\n",
    "在每轮中完整遍历一次训练数据集，不断迭代从中获取小批量训练数据集，对于每个小批量训练数据集执行如下步骤：\n",
    "* 获取小批量样本\n",
    "* 获取样本预测\n",
    "* 计算损失\n",
    "* 反向传播，优化更新参数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a348eb6-edb2-4bba-8b49-3a21472f0b39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss 0.032673\n",
      "epoch 2, loss 0.000117\n",
      "epoch 3, loss 0.000052\n",
      "w: [ 1.9997011 -3.3994913], b: 4.199641704559326\n",
      "w true: tensor([ 2.0000, -3.4000]), b true: 4.199999809265137\n"
     ]
    }
   ],
   "source": [
    "lr = 0.03      # 学习率\n",
    "num_epochs = 3 # 学习轮次\n",
    "net = linreg   # 神经网络\n",
    "lossfn = squared_loss # 损失函数\n",
    "batch_size = 10 # 批次大小\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for X, y in data_iter(batch_size, features, labels):\n",
    "        y_pred = net(X, w, b)\n",
    "        loss = lossfn(y_pred, y)\n",
    "        # loss 的形状是[batch_size, 1]，不是一个标量\n",
    "        # loss 中的所有元素想加，并以此计算关于[w, b]的梯度\n",
    "        loss.sum().backward()\n",
    "        # 使用参数的梯度更新参数\n",
    "        sgd([w, b], lr, batch_size)\n",
    "    # 完成一轮训练后，打印训练数据的拟合指标数值\n",
    "    with torch.no_grad():\n",
    "        train_loss = lossfn(net(features, w, b), labels)\n",
    "        print(f'epoch {epoch + 1}, loss {float(train_loss.mean()):f}')\n",
    "print(f'w: {w.detach().numpy()}, b: {b.detach().numpy()}')\n",
    "print(f'w true: {true_w}, b true: {true_b}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c247ac28-79e7-49f1-890d-fdeeb8bf7166",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
